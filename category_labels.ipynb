{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    #mount drive, set base path\n",
    "    drive.mount(\"/gdrive\")\n",
    "    base_path = '/gdrive/MyDrive/nma_dl_metamorphs/data/multi_dsprites'\n",
    "except:\n",
    "    base_path = './'\n",
    "from pathlib import Path\n",
    "import random\n",
    "from random import randint, choice\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum categories to bin the data\n",
    "MAXCATEGORIES = 10\n",
    "train_obj_prefix = 'training_objareas'\n",
    "val_obj_prefix = 'validation_objareas'\n",
    "test_obj_prefix = 'test_objareas'\n",
    "train_img_prefix = 'training_imgareas'\n",
    "val_img_prefix = 'validation_imgareas'\n",
    "test_img_prefix = 'test_imgareas'\n",
    "\n",
    "suffix = '_rand4_unique.npy'\n",
    "catstr = f'_cat{MAXCATEGORIES}'\n",
    "data_path = Path(base_path).joinpath('processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the object areas\n",
    "\n",
    "train_obj_area_path = Path(data_path).joinpath(train_obj_prefix + suffix)\n",
    "val_obj_area_path = Path(data_path).joinpath(val_obj_prefix + suffix)\n",
    "test_obj_area_path = Path(data_path).joinpath(test_obj_prefix + suffix)\n",
    "\n",
    "train_img_area_path = Path(data_path).joinpath(train_img_prefix + suffix)\n",
    "val_img_area_path = Path(data_path).joinpath(val_img_prefix + suffix)\n",
    "test_img_area_path = Path(data_path).joinpath(test_img_prefix + suffix)\n",
    "\n",
    "\n",
    "training_obj_area = np.load(train_obj_area_path)\n",
    "val_obj_area = np.load(val_obj_area_path)\n",
    "test_obj_area = np.load(test_obj_area_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect the min and max ranges of each split of the data (and mean just to have it)\n",
    "training_min_area = training_obj_area.min()\n",
    "training_max_area = training_obj_area.max()\n",
    "training_mean_area = training_obj_area.mean()\n",
    "\n",
    "val_min_area = val_obj_area.min()\n",
    "val_max_area = val_obj_area.max()\n",
    "val_mean_area = val_obj_area.mean()\n",
    "\n",
    "test_min_area = test_obj_area.min()\n",
    "test_max_area = test_obj_area.max()\n",
    "test_mean_area = test_obj_area.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train min area 0.0126953125, max area 0.345947265625, mean area 0.10607466796875\n",
      "val min area 0.0126953125, max area 0.323486328125, mean area 0.105957373046875\n",
      "test min area 0.012939453125, max area 0.3251953125, mean area 0.1065801025390625\n"
     ]
    }
   ],
   "source": [
    "#print them out\n",
    "print(f'train min area {training_min_area}, max area {training_max_area}, mean area {training_mean_area}')\n",
    "print(f'val min area {val_min_area}, max area {val_max_area}, mean area {val_mean_area}')\n",
    "print(f'test min area {test_min_area}, max area {test_max_area}, mean area {test_mean_area}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the min across all data and the max accross all data for the range to make the bins\n",
    "min_bin = np.min([training_min_area, val_min_area, test_min_area])\n",
    "max_bin = np.max([training_max_area, val_max_area, test_max_area])\n",
    "bins = np.linspace(min_bin, max_bin, MAXCATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the real numbers to categories 1..MAX_CATEGORIES\n",
    "train_cat = np.digitize(training_obj_area, bins)-1\n",
    "val_cat = np.digitize(val_obj_area, bins)-1\n",
    "test_cat = np.digitize(test_obj_area, bins)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01269531 0.04972331 0.0867513  0.1237793  0.16080729 0.19783529\n",
      " 0.23486328 0.27189128 0.30891927 0.34594727]\n",
      "[0.14355469 0.02734375 0.23510742 0.03393555 0.03173828 0.12646484\n",
      " 0.09960938 0.05322266 0.11230469 0.0769043 ]\n",
      "[3 0 6 0 0 3 2 1 2 1]\n",
      "\n",
      "\n",
      "[0.01269531 0.04972331 0.0867513  0.1237793  0.16080729 0.19783529\n",
      " 0.23486328 0.27189128 0.30891927 0.34594727]\n",
      "[0.13525391 0.22021484 0.1340332  0.0546875  0.203125   0.16723633\n",
      " 0.13476562 0.05664062 0.1809082  0.02270508]\n",
      "[3 5 3 1 5 4 3 1 4 0]\n",
      "\n",
      "\n",
      "[0.01269531 0.04972331 0.0867513  0.1237793  0.16080729 0.19783529\n",
      " 0.23486328 0.27189128 0.30891927 0.34594727]\n",
      "[0.17700195 0.11547852 0.05566406 0.03369141 0.18115234 0.04223633\n",
      " 0.08374023 0.14208984 0.1159668  0.07958984]\n",
      "[4 2 1 0 4 0 1 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "#have a lot at what we got\n",
    "print(bins)\n",
    "print(training_obj_area[0:10])\n",
    "print(train_cat[0:10])\n",
    "print(\"\\n\")\n",
    "print(bins)\n",
    "print(val_obj_area[0:10])\n",
    "print(val_cat[0:10])\n",
    "print(\"\\n\")\n",
    "print(bins)\n",
    "print(test_obj_area[0:10])\n",
    "print(test_cat[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out the categories.\n",
    "save_path = Path(data_path).joinpath(train_obj_prefix + catstr + suffix)\n",
    "np.save(save_path, train_cat)\n",
    "\n",
    "save_path = Path(data_path).joinpath(val_obj_prefix + catstr + suffix)\n",
    "np.save(save_path, val_cat)\n",
    "\n",
    "save_path = Path(data_path).joinpath(test_obj_prefix + catstr + suffix)\n",
    "np.save(save_path, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#can we read it back\n",
    "readback_test_cat = np.load(save_path)\n",
    "print(readback_test_cat[0:10]==test_cat[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat for img areas\n",
    "\n",
    "training_img_area = np.load(train_img_area_path)\n",
    "val_img_area = np.load(val_img_area_path)\n",
    "test_img_area = np.load(test_img_area_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect the min and max ranges of each split of the data (and mean just to have it)\n",
    "training_min_area = training_img_area.min()\n",
    "training_max_area = training_img_area.max()\n",
    "training_mean_area = training_img_area.mean()\n",
    "\n",
    "val_min_area = val_img_area.min()\n",
    "val_max_area = val_img_area.max()\n",
    "val_mean_area = val_img_area.mean()\n",
    "\n",
    "test_min_area = test_img_area.min()\n",
    "test_max_area = test_img_area.max()\n",
    "test_mean_area = test_img_area.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train min area 0.0126953125, max area 0.29345703125, mean area 0.09464724609375\n",
      "val min area 0.0126953125, max area 0.28271484375, mean area 0.094794189453125\n",
      "test min area 0.012939453125, max area 0.271240234375, mean area 0.0952012939453125\n"
     ]
    }
   ],
   "source": [
    "#print them out\n",
    "print(f'train min area {training_min_area}, max area {training_max_area}, mean area {training_mean_area}')\n",
    "print(f'val min area {val_min_area}, max area {val_max_area}, mean area {val_mean_area}')\n",
    "print(f'test min area {test_min_area}, max area {test_max_area}, mean area {test_mean_area}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the min across all data and the max accross all data for the range to make the bins\n",
    "min_bin = np.min([training_min_area, val_min_area, test_min_area])\n",
    "max_bin = np.max([training_max_area, val_max_area, test_max_area])\n",
    "bins = np.linspace(min_bin, max_bin, MAXCATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the real numbers to categories 1..MAX_CATEGORIES\n",
    "train_cat = np.digitize(training_img_area, bins)-1\n",
    "val_cat = np.digitize(val_img_area, bins)-1\n",
    "test_cat = np.digitize(test_img_area, bins)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01269531 0.04389106 0.07508681 0.10628255 0.1374783  0.16867405\n",
      " 0.19986979 0.23106554 0.26226128 0.29345703]\n",
      "[0.14355469 0.02734375 0.20263672 0.03393555 0.03173828 0.12548828\n",
      " 0.09887695 0.05322266 0.10644531 0.06152344]\n",
      "[4 0 6 0 0 3 2 1 3 1]\n",
      "\n",
      "\n",
      "[0.01269531 0.04389106 0.07508681 0.10628255 0.1374783  0.16867405\n",
      " 0.19986979 0.23106554 0.26226128 0.29345703]\n",
      "[0.1340332  0.17407227 0.12890625 0.0546875  0.203125   0.13208008\n",
      " 0.11328125 0.05664062 0.17480469 0.02270508]\n",
      "[3 5 3 1 6 3 3 1 5 0]\n",
      "\n",
      "\n",
      "[0.01269531 0.04389106 0.07508681 0.10628255 0.1374783  0.16867405\n",
      " 0.19986979 0.23106554 0.26226128 0.29345703]\n",
      "[0.13452148 0.09643555 0.05566406 0.03369141 0.16308594 0.04223633\n",
      " 0.0769043  0.13134766 0.10693359 0.06762695]\n",
      "[3 2 1 0 4 0 2 3 3 1]\n"
     ]
    }
   ],
   "source": [
    "#have a lot at what we got\n",
    "print(bins)\n",
    "print(training_img_area[0:10])\n",
    "print(train_cat[0:10])\n",
    "print(\"\\n\")\n",
    "print(bins)\n",
    "print(val_img_area[0:10])\n",
    "print(val_cat[0:10])\n",
    "print(\"\\n\")\n",
    "print(bins)\n",
    "print(test_img_area[0:10])\n",
    "print(test_cat[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out the categories.\n",
    "save_path = Path(data_path).joinpath(train_img_prefix + catstr + suffix)\n",
    "np.save(save_path, train_cat)\n",
    "\n",
    "save_path = Path(data_path).joinpath(val_img_prefix + catstr + suffix)\n",
    "np.save(save_path, val_cat)\n",
    "\n",
    "save_path = Path(data_path).joinpath(test_img_prefix + catstr + suffix)\n",
    "np.save(save_path, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#can we read it back\n",
    "readback_test_cat = np.load(save_path)\n",
    "print(readback_test_cat[0:10]==test_cat[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11205068\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 13 14:53 test_imgareas_10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root     400128 Aug 13 14:53 training_imgareas_10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 13 14:53 validation_imgareas_10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 13 14:51 test_objareas_10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root     400128 Aug 13 14:51 training_objareas_10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 13 14:51 validation_objareas_10_rand4_unique.npy\r\n",
      "drwxrwxr-x 6 1000 1000       4096 Aug 13 14:49 ..\r\n",
      "drwxrwxr-x 2 1000 1000       4096 Aug 13 14:47 .\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 12 21:32 test_objareas_cat10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root     400128 Aug 12 21:32 training_objareas_cat10_rand4_unique.npy\r\n",
      "-rw-r--r-- 1 root root      80128 Aug 12 21:32 validation_objareas_cat10_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_imgareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_objareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_objcounts_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  327680096 Aug  9 02:15 test_masks_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  491520096 Aug  9 02:15 test_images_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_imgareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_objareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_objcounts_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  327680096 Aug  9 02:15 validation_masks_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  491520096 Aug  9 02:15 validation_images_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_imgareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_objareas_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_objcounts_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000 1638400096 Aug  9 02:15 training_masks_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000 2457600096 Aug  9 02:15 training_images_rand4_unique.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_imgareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_objareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 test_objcounts_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  327680096 Aug  9 02:15 test_masks_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  491520096 Aug  9 02:15 test_images_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_imgareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_objareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000      80080 Aug  9 02:15 validation_objcounts_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  327680096 Aug  9 02:15 validation_masks_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000  491520096 Aug  9 02:15 validation_images_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_imgareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_objareas_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000     400080 Aug  9 02:15 training_objcounts_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000 1638400096 Aug  9 02:15 training_masks_rand4.npy\r\n",
      "-rw-rw-r-- 1 1000 1000 2457600096 Aug  9 02:15 training_images_rand4.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lat processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
